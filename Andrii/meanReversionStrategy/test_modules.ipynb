{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from timeit import timeit\n",
    "import sys\n",
    "import os\n",
    "import seaborn\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(10**8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "global DataFrequency\n",
    "\n",
    "DataFrequency = '1T'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/6hvfrncn0gb3rk22vwnq62gh0000gn/T/ipykernel_503/4292884806.py:268: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  inp_data.beautiful_time = pd.date_range(pd.Timestamp(inp_data.index.min()), pd.Timestamp(inp_data.index.min()) + pd.Timedelta(f\"{inp_data.shape[0] - 1}T\"), freq='1T')\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 42.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid len = 225000\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1545 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3830ad4d361d45dfa179d6803403577d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_name = 'AUDCAD.csv'\n",
    "\n",
    "PAIR_NAME = file_name.split('.')[0]\n",
    "if not os.access('backTEST', os.F_OK):\n",
    "    os.mkdir('backTEST')\n",
    "\n",
    "if not os.access(f'backTEST/{PAIR_NAME}', os.F_OK):\n",
    "    os.mkdir(f'backTEST/{PAIR_NAME}')\n",
    "\n",
    "inp_data = pd.read_csv(f'testData/{file_name}', index_col=1)\n",
    "# inp_data = pd.read_csv('testData/EURGBP.csv', index_col=0)\n",
    "inp_data.index = pd.to_datetime(inp_data.index)\n",
    "\n",
    "\"\"\"EURGBP columns rename\"\"\"\n",
    "# inp_data.rename(columns={'Open': 'open', 'Close': 'close', 'High': 'high', 'Low': 'low'}, inplace=True)\n",
    "\"\"\"DATABASE columns drop\"\"\"\n",
    "inp_data.drop(['instrument', 'volume', 'average', 'barCount'], axis=1, inplace=True)\n",
    "\n",
    "def create_grid(pam_grid_obj):\n",
    "    CAP = 100_000\n",
    "    slippage = 10\n",
    "    BuyLossPercent = pam_grid_obj['BuyLossPercent']\n",
    "    SellLossPercent = pam_grid_obj['BuyLossPercent']\n",
    "    BuyTakePercent = pam_grid_obj['BuyTakePercent']\n",
    "    SellTakePercent = pam_grid_obj['BuyTakePercent']\n",
    "    MaxHold = pam_grid_obj['MaxHold']\n",
    "    WindowRoll = pam_grid_obj['WindowRoll']\n",
    "    Y_STD = pam_grid_obj['Y_STD']\n",
    "\n",
    "\n",
    "    # Массив параметров\n",
    "    PARAMS = {'Capital': CAP,\n",
    "              'slippage': slippage,\n",
    "              'slippagePerCap': slippage / CAP,\n",
    "              'window_rolling': WindowRoll,\n",
    "              'Y_threshold': Y_STD,\n",
    "              'max_hold_period': MaxHold,\n",
    "              'stopLossesPercent':{\n",
    "                  'BuyLossPercent': BuyLossPercent / 100,\n",
    "                  'SellLossPercent': SellLossPercent / 100,\n",
    "              },\n",
    "              'takePercent':{\n",
    "                  'SellTakePercent': BuyTakePercent / 100,\n",
    "                  'BuyTakePercent': SellTakePercent / 100,\n",
    "              },\n",
    "              'shift_param': int(pd.Timedelta(WindowRoll) / pd.Timedelta(DataFrequency)),\n",
    "              'time_barrier_param': int(pd.Timedelta(MaxHold) / pd.Timedelta(DataFrequency))\n",
    "              }\n",
    "    del CAP, slippage, BuyLossPercent, SellLossPercent, BuyTakePercent, SellTakePercent, MaxHold, WindowRoll, Y_STD\n",
    "    return PARAMS\n",
    "\n",
    "\n",
    "def calculate_max_drawdown(PNL_SERIES, dollars=True):\n",
    "    \"\"\"\n",
    "    solution by Marco de Prado\n",
    "    :param PNL_SERIES:\n",
    "    :param dollars:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dropout_df = PNL_SERIES.to_frame('pnl')\n",
    "    dropout_df['hwm'] = dropout_df.expanding().max()\n",
    "    df0 = dropout_df.groupby('hwm').min().reset_index()\n",
    "    df0.columns = ['hwm', 'min']\n",
    "    df0 = df0[df0['hwm'] > df0['min']]\n",
    "    if dollars:\n",
    "        dd = df0['hwm'] - df0['min']\n",
    "    else:\n",
    "        dd = df0['min'] / df0['hwm']\n",
    "\n",
    "    return max(dd)\n",
    "\n",
    "def _estimator(data_frame, params_dict, show=False):\n",
    "    DF_lines = []\n",
    "    save_frame = data_frame.copy()\n",
    "    # Считается параметр насколько нужно обрезать данные для адекватности сглаживания\n",
    "\n",
    "    # Скользящее среднее\n",
    "    data_frame.loc[:, 'rolling_mean'] = data_frame.loc[:, 'close'].rolling(params_dict['window_rolling']).mean()\n",
    "\n",
    "    # Скользящее отклонение\n",
    "    data_frame.loc[:, 'rolling_std'] = data_frame.loc[:, 'close'].rolling(params_dict['window_rolling']).std()\n",
    "\n",
    "    # Отсечение данных имеющих\n",
    "    # data_frame.drop(data_frame.index[:params_dict['shift_param']], axis=0, inplace=True)\n",
    "\n",
    "    # Верхний уровень BBand\n",
    "    data_frame.loc[:, 'HighBBand'] = round(data_frame.loc[:, 'rolling_mean'] + ((params_dict['Y_threshold'] / 100) * data_frame.loc[:, 'rolling_std']),5)\n",
    "\n",
    "    # Нижний уровень BBand\n",
    "    data_frame.loc[:, 'LowBBand'] = round(data_frame.loc[:, 'rolling_mean'] - ((params_dict['Y_threshold'] / 100) * data_frame.loc[:, 'rolling_std']),5)\n",
    "\n",
    "    # Добавление номера линии для удобства\n",
    "    data_frame['line_number'] = range(1, data_frame.shape[0] + 1)\n",
    "\n",
    "\n",
    "    # correct_borders2 = data_frame.resample(DataFrequency).first().open.shift(-1 * params_dict['time_barrier_param']).rolling(params_dict['window_rolling']).count()\n",
    "    # correct_borders = tuple(data_frame.open.shift(-1 * params_dict['time_barrier_param']).rolling(params_dict['window_rolling']).count() == float(params_dict['shift_param']))\n",
    "    ab = list(zip(data_frame.copy().resample(DataFrequency).first().open.shift(-1 * params_dict['time_barrier_param'] - 1).rolling(params_dict['window_rolling']).count().values, data_frame.copy().resample(DataFrequency).first().index))\n",
    "    ab = pd.DataFrame(ab)\n",
    "    # print('AB',len(ab))\n",
    "    # print('DF',len(data_frame))\n",
    "    ab.columns = ['value', 'time']\n",
    "    ab.index = ab.time\n",
    "    ab = ab.drop(['time'], axis=1)\n",
    "\n",
    "    correct_borders = tuple(pd.merge(data_frame, ab, left_index=True, right_index=True).value == params_dict['shift_param'])\n",
    "    # print('CB',len(correct_borders))\n",
    "    dot_low_tuple = tuple(data_frame.low)\n",
    "    dot_high_tuple = tuple(data_frame.high)\n",
    "    dot_close_tuple = tuple(data_frame.close)\n",
    "    LowBBand_tuple = tuple(data_frame.LowBBand)\n",
    "    HighBBand_tuple = tuple(data_frame.HighBBand)\n",
    "\n",
    "    cycle_buffer = -10\n",
    "    ISX = 0\n",
    "    if show:\n",
    "        tqdm_bar = tqdm(total=data_frame.shape[0])\n",
    "\n",
    "    while ISX < (data_frame.shape[0] / 1.1) and (cycle_buffer != ISX):\n",
    "        openLogic = OpenPosition(dot_low_tuple=dot_low_tuple, dot_high_tuple=dot_high_tuple,\n",
    "                     LowBBand_tuple=LowBBand_tuple, HighBBand_tuple=HighBBand_tuple,\n",
    "                     arrow_index=ISX, openParams=params_dict, correct_borders=correct_borders)\n",
    "\n",
    "        openLogic['open_time'] = data_frame.index[openLogic['open_index']]\n",
    "        closeLogic = HoldingPosition(open_logic=openLogic, dot_close_tuple=dot_close_tuple,\n",
    "                        dot_high_tuple=dot_high_tuple, dot_low_tuple=dot_low_tuple,\n",
    "                        holdParams=params_dict, arrow_index=openLogic['open_index'] + 1, time_border_counter=0)\n",
    "\n",
    "        closeLogic['close_time'] = data_frame.index[closeLogic['close_index']]\n",
    "        summary_dict = openLogic | closeLogic\n",
    "        DF_lines.append(summary_dict)\n",
    "\n",
    "        cycle_buffer = ISX\n",
    "        ISX = closeLogic['close_index']\n",
    "        if show:\n",
    "            tqdm_bar.update(ISX - tqdm_bar.last_print_n)\n",
    "\n",
    "    dfResults = pd.DataFrame(DF_lines)\n",
    "    dfResults[\"profit\"] = dfResults[\"position\"] * (dfResults[\"close_price\"] - dfResults[\"open_price\"]) - params_dict[\"slippage\"] if (dfResults[\"type_operation\"] == 'BUY').bool else abs(dfResults[\"position\"]) * (dfResults[\"open_price\"] - dfResults[\"close_price\"]) - params_dict[\"slippage\"]\n",
    "    dfResults.index = dfResults.close_time\n",
    "    pnl_series = dfResults[\"profit\"].cumsum()\n",
    "\n",
    "\n",
    "    optimizePar = round(pnl_series[-1] / calculate_max_drawdown(pnl_series + params_dict['Capital']), 4)\n",
    "    params_dict_opt = params_dict.copy()\n",
    "    params_dict_opt['result'] = optimizePar\n",
    "    return [dfResults, data_frame, optimizePar, params_dict_opt]\n",
    "\n",
    "def OpenPosition(dot_low_tuple, dot_high_tuple, LowBBand_tuple, HighBBand_tuple, arrow_index, openParams, correct_borders):\n",
    "    \"\"\"\n",
    "    Проверяет возможно ли открыть сделку. В случае возможности возвращает информацию об открытой сделки\n",
    "    :param current_dot:\n",
    "    :param arrow_index:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Задается вид словаря описывающего информацию об открытии сделки\n",
    "    ret_dict = {'type_operation': None,\n",
    "                'position': None,\n",
    "                'open_price': None,\n",
    "                'open_index': None,\n",
    "                'stop_loss_border': None,\n",
    "                'take_profit_border': None\n",
    "                }\n",
    "    if arrow_index > len(dot_low_tuple):\n",
    "        return 'InCorrectData'\n",
    "    # Проверка о пересечении нижней границы\n",
    "    if (dot_low_tuple[arrow_index] < LowBBand_tuple[arrow_index]) and (correct_borders[arrow_index + 1]):\n",
    "        ret_dict['type_operation'] = 'BUY'\n",
    "        ret_dict['position'] = 1 * (openParams['Capital'] / LowBBand_tuple[arrow_index])\n",
    "        ret_dict['open_price'] = LowBBand_tuple[arrow_index]\n",
    "        ret_dict['open_index'] = arrow_index\n",
    "        ret_dict['stop_loss_border'] = round(LowBBand_tuple[arrow_index] * (1 - openParams['stopLossesPercent']['BuyLossPercent']), 5)\n",
    "        ret_dict['take_profit_border'] = round(LowBBand_tuple[arrow_index] * (1 + openParams['takePercent']['BuyTakePercent']), 5)\n",
    "\n",
    "        return ret_dict\n",
    "    # Проверка о пересечении верхней границы\n",
    "    if (dot_high_tuple[arrow_index] > HighBBand_tuple[arrow_index]) and (correct_borders[arrow_index + 1]):\n",
    "        ret_dict['type_operation'] = 'SELL'\n",
    "        ret_dict['position'] = -1 * (openParams['Capital'] / HighBBand_tuple[arrow_index])\n",
    "        ret_dict['open_price'] = HighBBand_tuple[arrow_index]\n",
    "        ret_dict['open_index'] = arrow_index\n",
    "\n",
    "        ret_dict['stop_loss_border'] = round(HighBBand_tuple[arrow_index] * (1 + openParams['stopLossesPercent']['SellLossPercent']), 5)\n",
    "        ret_dict['take_profit_border'] = round(HighBBand_tuple[arrow_index] * (1 - openParams['takePercent']['SellTakePercent']), 5)\n",
    "        return ret_dict\n",
    "    else:\n",
    "        return OpenPosition(dot_low_tuple=dot_low_tuple, dot_high_tuple=dot_high_tuple,\n",
    "                            LowBBand_tuple=LowBBand_tuple, HighBBand_tuple=HighBBand_tuple,\n",
    "                            arrow_index=arrow_index + 1, openParams=openParams, correct_borders=correct_borders)\n",
    "\n",
    "def HoldingPosition(open_logic, dot_close_tuple, dot_high_tuple, dot_low_tuple, holdParams, arrow_index, time_border_counter):\n",
    "    if open_logic['type_operation'] == 'BUY':\n",
    "        if time_border_counter - 1 > holdParams['time_barrier_param']:\n",
    "            return {'type_holding': 'endPeriod', 'close_price': dot_close_tuple[arrow_index], 'close_index': arrow_index}\n",
    "        elif dot_low_tuple[arrow_index] <= open_logic['stop_loss_border']:\n",
    "            return {'type_holding': 'stopLoss', 'close_price': open_logic['stop_loss_border'], 'close_index': arrow_index}\n",
    "        elif dot_high_tuple[arrow_index] >= open_logic['take_profit_border']:\n",
    "            return {'type_holding': 'takeProfit', 'close_price': open_logic['take_profit_border'], 'close_index': arrow_index}\n",
    "\n",
    "        else:\n",
    "            return HoldingPosition(open_logic=open_logic, dot_close_tuple=dot_close_tuple, dot_high_tuple=dot_high_tuple,\n",
    "                                   dot_low_tuple=dot_low_tuple, holdParams=holdParams,\n",
    "                                   arrow_index=arrow_index + 1, time_border_counter=time_border_counter + 1)\n",
    "\n",
    "    if open_logic['type_operation'] == 'SELL':\n",
    "        if time_border_counter - 1 > holdParams['time_barrier_param']:\n",
    "            return {'type_holding': 'endPeriod', 'close_price': dot_close_tuple[arrow_index], 'close_index': arrow_index}\n",
    "        elif dot_low_tuple[arrow_index] <= open_logic['take_profit_border']:\n",
    "            return {'type_holding': 'takeProfit', 'close_price': open_logic['take_profit_border'], 'close_index': arrow_index}\n",
    "        elif dot_high_tuple[arrow_index] >= open_logic['stop_loss_border']:\n",
    "            return {'type_holding': 'stopLoss', 'close_price': open_logic['stop_loss_border'], 'close_index': arrow_index}\n",
    "        else:\n",
    "            return HoldingPosition(open_logic=open_logic, dot_close_tuple=dot_close_tuple, dot_high_tuple=dot_high_tuple,\n",
    "                                   dot_low_tuple=dot_low_tuple, holdParams=holdParams,\n",
    "                                   arrow_index=arrow_index + 1, time_border_counter=time_border_counter + 1)\n",
    "def plotter(test_df, qqq):\n",
    "    plt.figure(figsize=(16,16))\n",
    "\n",
    "    ax1 = plt.subplot(4,1,1)\n",
    "    ax1.set_title('pnl graph')\n",
    "    plt.step(test_df.open_time, test_df.profit.cumsum().values)\n",
    "    ax2 = plt.subplot(4,1,2, sharex=ax1)\n",
    "    ax2.set_title('Bbands')\n",
    "    plt.plot(qqq.open, label='open', alpha=.5)\n",
    "    plt.plot(qqq.high, label='high', alpha=.7, color='red')\n",
    "    plt.plot(qqq.low, label='close', alpha=.7, color='yellow')\n",
    "    plt.plot(qqq.HighBBand, label='HighBand', alpha=.6, color='blue')\n",
    "    plt.plot(qqq.LowBBand, label='LowBand', alpha=.6, color='blue')\n",
    "    plt.legend(loc='lower right')\n",
    "    ax3 = plt.subplot(4,1,3, sharex=ax1)\n",
    "    ax3.set_title('trades histogram')\n",
    "    for _ in range(test_df.shape[0]):\n",
    "        if test_df.iloc[_].type_operation == 'BUY':\n",
    "            plt.axvline(x=test_df.iloc[_].open_time, color='green', alpha=.6, linewidth=.5)\n",
    "            plt.axvline(x=test_df.iloc[_].close_time, color='green', alpha=.6, linewidth=.5)\n",
    "        if test_df.iloc[_].type_operation == 'SELL':\n",
    "            plt.axvline(x=test_df.iloc[_].open_time, color='red', alpha=.6, linewidth=.5)\n",
    "            plt.axvline(x=test_df.iloc[_].close_time, color='red', alpha=.6, linewidth=.5)\n",
    "        plt.hlines(xmin=test_df.iloc[_].open_time, xmax=test_df.iloc[_].close_time, y=test_df.open_price[_], color='black', linestyles='-')\n",
    "    ax4 = plt.subplot(4,1,4, sharex=ax1)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def lightPlotter(test_df, qqq, final=False, show=False):\n",
    "    plt.figure(figsize=(16,16))\n",
    "    if not final:\n",
    "        plt.title('InSample')\n",
    "    if final:\n",
    "        plt.title('OutOfSample')\n",
    "    ax1 = plt.subplot(2, 1, 1)\n",
    "    ax1.set_title('pnl graph')\n",
    "    plt.step(test_df.open_time, test_df.profit.cumsum().values)\n",
    "    ax2 = plt.subplot(2,1,2, sharex=ax1)\n",
    "    ax2.set_title('Bbands')\n",
    "    plt.plot(qqq.open, label='open', alpha=.5)\n",
    "    plt.plot(qqq.HighBBand, label='HighBand', alpha=.6, color='blue')\n",
    "    plt.plot(qqq.rolling_mean, label='MovingAverage', alpha=1, color='red')\n",
    "    plt.plot(qqq.LowBBand, label='LowBand', alpha=.6, color='yellow')\n",
    "    plt.legend(loc='lower right')\n",
    "    if not final:\n",
    "        plt.savefig(f'backTEST/{PAIR_NAME}/bestInSample_{PAIR_NAME}.jpeg')\n",
    "    if final:\n",
    "        plt.savefig(f'backTEST/{PAIR_NAME}/outSample_{PAIR_NAME}.jpeg')\n",
    "    if not show:\n",
    "        plt.close()\n",
    "\n",
    "\"\"\"WAY TO DELETE HOLIDAYS\"\"\"\n",
    "inp_data.beautiful_time = pd.date_range(pd.Timestamp(inp_data.index.min()), pd.Timestamp(inp_data.index.min()) + pd.Timedelta(f\"{inp_data.shape[0] - 1}T\"), freq='1T')\n",
    "inp_data.index = inp_data.beautiful_time\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"BuyLossPercent\": np.linspace(.1, 1.2, 10),\n",
    "    #\"SellLossPercent\": [20, 30, 40],\n",
    "    \"BuyTakePercent\": np.linspace(.1, 1.2, 10),\n",
    "    #\"SellTakePercent\": [20, 30, 40],\n",
    "    \"MaxHold\": [str(int(x))+'T' for x in np.linspace(100, 2450, 15)],\n",
    "    \"WindowRoll\": [str(int(x))+'T' for x in np.linspace(100, 650, 15)],\n",
    "    \"Y_STD\": np.linspace(10, 300, 10)\n",
    "          }\n",
    "grid = ParameterGrid(params)\n",
    "print(f\"Grid len = {len(grid)}\")\n",
    "# shuffled = pd.DataFrame(grid).sample(frac=1, random_state=20).reset_index(drop=True) # OLD PARAMS\n",
    "shuffled = pd.DataFrame(grid).sample(frac=1, random_state=21).reset_index(drop=True)\n",
    "\n",
    "# SHIFT = 400_000\n",
    "# RESULT = Parallel(n_jobs=-1, verbose=5, prefer=\"threads\", require='sharedmem')(delayed(_estimator)(inp_data.copy().loc['2019-01-01': '2020-01-01'], create_grid(dict(shuffled.iloc[paramArrow])), show=False) for paramArrow in tqdm(range(shuffled[:45].shape[0]))) # OLD GRID\n",
    "RESULT = Parallel(n_jobs=-1, verbose=5, prefer=\"threads\", require='sharedmem')(delayed(_estimator)(inp_data.copy().loc['2019-01-01': '2020-01-01'], create_grid(dict(shuffled.iloc[paramArrow])), show=False) for paramArrow in tqdm(range(shuffled[:1545].shape[0])))\n",
    "\n",
    "optParams = [_[2] for _ in RESULT]\n",
    "optParams = shuffled.iloc[optParams.index(max(optParams))]\n",
    "PARAMS_DF = pd.DataFrame([_[3] for _ in RESULT])\n",
    "print('OPTIMAL_PARAMS:\\n', optParams)\n",
    "df, preprocessed_data, optimizePar, total_df = _estimator(data_frame=inp_data.copy().loc['2019-01-01': '2020-01-01'], params_dict=create_grid(dict(optParams)), show=True)\n",
    "# plotter(df, preprocessed_data)\n",
    "lightPlotter(df, preprocessed_data)\n",
    "print('INSAMPLE')\n",
    "print(f\"\"\"Total trades: {df.shape[0]}\n",
    "Total pnl {round(df.profit.cumsum().iloc[-1], 3)}\n",
    "Positive trades: {round(df[df.profit > 0].shape[0] / df.shape[0], 3)}\n",
    "Negative trades: {round(df[df.profit < 0].shape[0] / df.shape[0], 3)}\n",
    "Long trades: {round(df[df.type_operation == 'BUY'].shape[0] / df.shape[0], 3)}\n",
    "Short trades: {round(df[df.type_operation == 'SELL'].shape[0] / df.shape[0], 3)}\n",
    "StopLoss closes: {round(df[df.type_holding == 'stopLoss'].shape[0] / df.shape[0], 3)}\n",
    "TakeProfit closes: {round(df[df.type_holding == 'takeProfit'].shape[0] / df.shape[0], 3)}\n",
    "endPeriod closes: {round(df[df.type_holding == 'endPeriod'].shape[0] / df.shape[0], 3)}\n",
    "\"\"\")\n",
    "\n",
    "with open(f'backTEST/{PAIR_NAME}/best_InSample_stat.txt', 'w') as file:\n",
    "    file.writelines(f\"\"\"\n",
    "        Total trades:, {df.shape[0]}\n",
    "        Total pnl, {round(df.profit.cumsum().iloc[-1], 3)}\n",
    "        Positive trades:, {round(df[df.profit > 0].shape[0] / df.shape[0], 3)}\n",
    "        Negative trades:, {round(df[df.profit < 0].shape[0] / df.shape[0], 3)}\n",
    "        Long trades:, {round(df[df.type_operation == 'BUY'].shape[0] / df.shape[0], 3)}\n",
    "        Short trades:, {round(df[df.type_operation == 'SELL'].shape[0] / df.shape[0], 3)}\n",
    "        StopLoss closes:, {round(df[df.type_holding == 'stopLoss'].shape[0] / df.shape[0], 3)}\n",
    "        TakeProfit closes:, {round(df[df.type_holding == 'takeProfit'].shape[0] / df.shape[0], 3)}\n",
    "        endPeriod closes:, {round(df[df.type_holding == 'endPeriod'].shape[0] / df.shape[0], 3)}\n",
    "        \"\"\")\n",
    "\n",
    "df, preprocessed_data, optimizePar, total_df = _estimator(data_frame=inp_data.copy().loc['2020-01-01': '2021-01-01'], params_dict=create_grid(dict(optParams)), show=True)\n",
    "# plotter(df, preprocessed_data)\n",
    "lightPlotter(df, preprocessed_data, final=True)\n",
    "print('OUTOFSAMPLE')\n",
    "print(f\"\"\"Total trades: {df.shape[0]}\n",
    "Total pnl {round(df.profit.cumsum().iloc[-1], 3)}\n",
    "Positive trades: {round(df[df.profit > 0].shape[0] / df.shape[0], 3)}\n",
    "Negative trades: {round(df[df.profit < 0].shape[0] / df.shape[0], 3)}\n",
    "Long trades: {round(df[df.type_operation == 'BUY'].shape[0] / df.shape[0], 3)}\n",
    "Short trades: {round(df[df.type_operation == 'SELL'].shape[0] / df.shape[0], 3)}\n",
    "StopLoss closes: {round(df[df.type_holding == 'stopLoss'].shape[0] / df.shape[0], 3)}\n",
    "TakeProfit closes: {round(df[df.type_holding == 'takeProfit'].shape[0] / df.shape[0], 3)}\n",
    "endPeriod closes: {round(df[df.type_holding == 'endPeriod'].shape[0] / df.shape[0], 3)}\n",
    "\"\"\")\n",
    "\n",
    "with open(f'backTEST/{PAIR_NAME}/outsample_stat.txt', 'w') as file:\n",
    "    file.writelines(f\"\"\"\n",
    "        Total trades:, {df.shape[0]}\n",
    "        Total pnl, {round(df.profit.cumsum().iloc[-1], 3)}\n",
    "        Positive trades:, {round(df[df.profit > 0].shape[0] / df.shape[0], 3)}\n",
    "        Negative trades:, {round(df[df.profit < 0].shape[0] / df.shape[0], 3)}\n",
    "        Long trades:, {round(df[df.type_operation == 'BUY'].shape[0] / df.shape[0], 3)}\n",
    "        Short trades:, {round(df[df.type_operation == 'SELL'].shape[0] / df.shape[0], 3)}\n",
    "        StopLoss closes:, {round(df[df.type_holding == 'stopLoss'].shape[0] / df.shape[0], 3)}\n",
    "        TakeProfit closes:, {round(df[df.type_holding == 'takeProfit'].shape[0] / df.shape[0], 3)}\n",
    "        endPeriod closes:, {round(df[df.type_holding == 'endPeriod'].shape[0] / df.shape[0], 3)}\n",
    "        \"\"\")\n",
    "\n",
    "df[\"own_time\"] = df.close_time - df.open_time\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.title('MarkOut')\n",
    "ax = plt.subplot(1,1,1)\n",
    "df.groupby(by='own_time').profit.mean().plot(marker='o', ax=ax)\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(PARAMS_DF).to_csv(f'backTEST/{PAIR_NAME}/result_{PAIR_NAME}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read data and unpack losses and takeProfits\n",
    "res = pd.read_csv(f\"backTEST/{PAIR_NAME}/result_{PAIR_NAME}.csv\", index_col=0)\n",
    "res[\"TakeProfit\"] = res.takePercent.aggregate(lambda x: ast.literal_eval(x)['SellTakePercent'])\n",
    "res[\"StopLoss\"] = res.stopLossesPercent.aggregate(lambda x: ast.literal_eval(x)['BuyLossPercent'])\n",
    "\n",
    "plot = res[['window_rolling', 'Y_threshold', 'max_hold_period', 'result', 'TakeProfit', 'StopLoss']]\n",
    "\n",
    "# Convert date type to floats\n",
    "plot.loc[:, 'window_rolling'] = plot.loc[:,'window_rolling'].aggregate(lambda x: pd.Timedelta(x).total_seconds())\n",
    "plot.loc[:, 'max_hold_period'] = plot.loc[:, 'max_hold_period'].aggregate(lambda x: pd.Timedelta(x).total_seconds())\n",
    "\n",
    "\n",
    "COLUMNS = plot.columns.values\n",
    "COLUMNS = np.delete(COLUMNS, np.where(COLUMNS == 'result'))\n",
    "\n",
    "# Scale data to normalize\n",
    "# scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "scaledPlot = pd.DataFrame(scaler.fit_transform(plot.values))\n",
    "scaledPlot.columns = plot.columns\n",
    "scaledPlot.index = plot.index\n",
    "scaledPlot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seaborn.set(rc={'figure.figsize': (11.7, 8.27)})\n",
    "seaborn.pairplot(data=scaledPlot, x_vars=COLUMNS, y_vars=f\"result\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Понижаем размерность\n",
    "pca = PCA(n_components = 2)\n",
    "XPCAreduced = pca.fit_transform(scaledPlot.drop('result', axis=1).values)\n",
    "pca.explained_variance_ratio_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sc = plt.scatter(x=XPCAreduced.T[0], y=XPCAreduced.T[1], c=scaledPlot['result'], cmap='Dark2')\n",
    "plt.colorbar(sc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"------\"\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random')\n",
    "scaledTSNE = tsne.fit_transform(scaledPlot.drop('result', axis=1).values)\n",
    "scaledTSNE.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sc = plt.scatter(x=scaledTSNE.T[0], y=scaledTSNE.T[1], c=scaledPlot['result'], cmap='Dark2')\n",
    "plt.colorbar(sc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://www.machinelearningmastery.ru/feature-extraction-techniques-d619b56e31be/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "embedding = LocallyLinearEmbedding(n_components=3)\n",
    "\n",
    "X_lle = embedding.fit_transform(scaledPlot.drop('result', axis=1).values)\n",
    "sc = plt.scatter(x=X_lle.T[1], y=X_lle.T[2], c=scaledPlot['result'], cmap='Dark2')\n",
    "plt.colorbar(sc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}